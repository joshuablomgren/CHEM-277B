{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e90fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchani\n",
    "import pyanitools as pya\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c88a22",
   "metadata": {},
   "source": [
    "# CHEM 277B - Final Project #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e404cd",
   "metadata": {},
   "source": [
    "For this project, we will develop a supervised learning artificial neural network (ANN) that predicts the energy of a molecular system given the coordinates of the molecules in the system. While solving the Schrodinger equation is computationally expensive, we will be using machine learning to predict the system's energy without solving the equation computationally. \n",
    "\n",
    "## Understanding the ANI-1 Dataset ##\n",
    "\n",
    "The ANI-1 dataset is a collection of 57,000 organic molecules with up to 8 heavy atoms. Let's look at the first subset of the dataset involving only one heavy atom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbeae41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:       /gdb11_s01/gdb11_s01-0\n",
      "  SMILES:   [H]C([H])([H])[H]\n",
      "  Symbols:  ['C', 'H', 'H', 'H', 'H']\n",
      "  Coordinates:  (5400, 5, 3)\n",
      "  Energies:     (5400,) \n",
      "\n",
      "Path:       /gdb11_s01/gdb11_s01-1\n",
      "  SMILES:   [H]N([H])[H]\n",
      "  Symbols:  ['N', 'H', 'H', 'H']\n",
      "  Coordinates:  (3600, 4, 3)\n",
      "  Energies:     (3600,) \n",
      "\n",
      "Path:       /gdb11_s01/gdb11_s01-2\n",
      "  SMILES:   [H]O[H]\n",
      "  Symbols:  ['O', 'H', 'H']\n",
      "  Coordinates:  (1800, 3, 3)\n",
      "  Energies:     (1800,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load ANI-1 dataset with 1 heavy atom\n",
    "ani_data = pya.anidataloader(\n",
    "    '/global/scratch/users/joshuablomgren/ANI-1_release/ani_gdb_s01.h5')\n",
    "\n",
    "# Loop over each data point in the dataset\n",
    "for data in ani_data:\n",
    "    # Extract information from the dataset\n",
    "    path = data['path']\n",
    "    coordinates = data['coordinates']\n",
    "    energies = data['energies']\n",
    "    species = data['species']\n",
    "    smiles = data['smiles']\n",
    "\n",
    "    # Print the information for this data point\n",
    "    print(\"Path:      \", path)\n",
    "    print(\"  SMILES:  \", \"\".join(smiles))\n",
    "    print(\"  Symbols: \", species)\n",
    "    print(\"  Coordinates: \", coordinates.shape)\n",
    "    print(\"  Energies:    \", energies.shape, \"\\n\")\n",
    "\n",
    "# Close the H5 data file\n",
    "ani_data.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af14f3e",
   "metadata": {},
   "source": [
    "From the information printed above, we can see from the shape of the coordinates that each molecule has several thousand different conformations given: (number of confirmations, number of atoms, 3-dimensions). For each confirmation, the energy of the system is also given, hence the size of energies is the same as the number of confirmations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4ab5d",
   "metadata": {},
   "source": [
    "## Subset 5 - 5 Heavy Atoms ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f823070",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pya.anidataloader('/global/scratch/users/joshuablomgren/ANI-1_release/ani_gdb_s05.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bea181b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n",
      "1813151\n"
     ]
    }
   ],
   "source": [
    "data_iter = data.__iter__()\n",
    "count = 0\n",
    "count_conformations = 0\n",
    "\n",
    "# iterate through all the molecules in data subset 5\n",
    "for mol in data_iter:\n",
    "    count += 1\n",
    "    count_conformations += len(mol['energies'])\n",
    "\n",
    "print(count)\n",
    "print(count_conformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317e4ae",
   "metadata": {},
   "source": [
    "In subset 5 of the ANI-1 dataset, there are **267** molecules that each have 5 heavy atoms. There are a total of **1,813,151** conformations in this subset, each of the molecules having a different number of given conformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651c590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:    /gdb11_s05/gdb11_s05-0\n",
      "  Smiles:       [H]N([H])C(C([H])([H])[H])(C([H])([H])[H])C([H])([H])[H]\n",
      "  Symbols:      ['C', 'C', 'C', 'C', 'N', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H']\n",
      "  Coordinates:  (10080, 16, 3)\n",
      "  Energies:     (10080,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_iter = data.__iter__()\n",
    "mols = next(data_iter)\n",
    "# Extract the data\n",
    "P = mols['path']\n",
    "X = mols['coordinates']\n",
    "E = mols['energies']\n",
    "S = mols['species']\n",
    "sm = mols['smiles']\n",
    "\n",
    "# Print the data\n",
    "print(\"Path:   \", P)\n",
    "print(\"  Smiles:      \",\"\".join(sm))\n",
    "print(\"  Symbols:     \", S)\n",
    "print(\"  Coordinates: \", X.shape)\n",
    "print(\"  Energies:    \", E.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3e1b0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Atomic Environment Vectors (AEV) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc6b6fe",
   "metadata": {},
   "source": [
    "AEVs, Atomic Environment Vectors, are feature vectors that encode the local chemical environment around an atom in a molecule. We will be using AEVs to transform the initial atomic configurations using symmetry functions before putting them in our neural network. In order to train a neural network for predicting molecular properties, it is important to ensure that the network is invariant to translations, rotations, and permutations of the atoms in a molecule, which can be achieved through computing AEVs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab16184",
   "metadata": {},
   "source": [
    "The `torchani` library provides a module called AEV Computer that computes the AEVs (Atomic Environment Vectors) of molecular structures. The `torchani.AEVComputer` class is initialized with certain parameters such as Rcr (cutoff radius for radial symmetry functions), Rca (cutoff radius for angular symmetry functions), and a set of hyperparameters such as EtaR, EtaA, Zeta, ShfR, ShfA, and ShfZ, which are used to compute the AEVs of molecular structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5072115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcr = 5.2\n",
    "EtaR = torch.tensor([16], dtype=torch.float)\n",
    "ShfR = torch.tensor([0.900000,1.168750,1.437500,1.706250,1.975000,2.243750,2.51250,2.781250,3.050000,3.318750,3.587500,3.856250,4.125000,4.39375,4.662500,4.931250])\n",
    "Rca = 3.5\n",
    "EtaA = torch.tensor([8], dtype=torch.float)\n",
    "ShfA = torch.tensor([0.900000,1.550000,2.200000,2.850000], dtype=torch.float)\n",
    "ShfZ = torch.tensor([0.19634954,0.58904862,0.9817477,1.3744468,1.7671459,2.1598449,2.552544,2.945243]) \n",
    "Zeta = torch.tensor([32], dtype=torch.float)\n",
    "symbols_order = ['H', 'C', 'N', 'O']\n",
    "num_symbols = len(symbols_order) # number of different atom symbols\n",
    "\n",
    "aev_computer = torchani.AEVComputer(Rcr, Rca, EtaR, ShfR, EtaA, Zeta, ShfA, ShfZ, num_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3be21933",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"H\": 0, \"C\": 1, \"N\": 2, \"O\": 3} # map atom types to integers\n",
    "symbols = np.array([mapping[atom] for atom in S]) #S the same S as symbols\n",
    "symbols = np.tile(symbols, (X.shape[0], 1)) \n",
    "symbols = torch.tensor(symbols)\n",
    "X = torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30de8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "aevs = aev_computer((symbols, X))[1]\n",
    "# input: tuple\n",
    "# symbols.shape: (Number of conformations, mapped atoms)\n",
    "# X.shape: (Number of conformations, atoms, 3)\n",
    "# output: SpeciesAEV object\n",
    "# output[0] : symbols\n",
    "# output[1].shape: (Number of conformations, number of atoms, num of AEV vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97285729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10080, 16, 384])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aevs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfefd38",
   "metadata": {},
   "source": [
    "The `AEVComputer` returns a SpeciesAEV object that contains the mapped atomic symbols as well as the AEVs for each atom. In this case, 384 AEVs are generated for each atom and are stored as `aevs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ecd64c",
   "metadata": {},
   "source": [
    "## Create AEVs for All Molecules in Subset 2 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc46f807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# AEV Computer hyperparameters\n",
    "Rcr = 5.2\n",
    "EtaR = torch.tensor([16], dtype=torch.float)\n",
    "ShfR = torch.tensor([0.900000,1.168750,1.437500,1.706250,1.975000,2.243750,2.51250,2.781250,3.050000,3.318750,3.587500,3.856250,4.125000,4.39375,4.662500,4.931250])\n",
    "Rca = 3.5\n",
    "EtaA = torch.tensor([8], dtype=torch.float)\n",
    "ShfA = torch.tensor([0.900000,1.550000,2.200000,2.850000], dtype=torch.float)\n",
    "ShfZ = torch.tensor([0.19634954,0.58904862,0.9817477,1.3744468,1.7671459,2.1598449,2.552544,2.945243]) \n",
    "Zeta = torch.tensor([32], dtype=torch.float)\n",
    "\n",
    "symbols_order = ['H', 'C', 'N', 'O']\n",
    "num_symbols = len(symbols_order) # number of different atom symbols\n",
    "\n",
    "aev_computer = torchani.AEVComputer(Rcr, Rca, EtaR, ShfR, EtaA, Zeta, ShfA, ShfZ, num_symbols)\n",
    "\n",
    "\n",
    "data = pya.anidataloader('/global/scratch/users/joshuablomgren/ANI-1_release/ani_gdb_s02.h5')\n",
    "data_iter = data.__iter__()\n",
    "\n",
    "# create lists to store the AEVs and energies for all molecules\n",
    "energies = []\n",
    "aevs_all = []\n",
    "\n",
    "mapping = {\"H\": 0, \"C\": 1, \"N\": 2, \"O\": 3} # map atom types to integers\n",
    "\n",
    "# iterate through all the molecules in data subset 5\n",
    "for mol in data_iter:\n",
    "    X = torch.tensor(mol['coordinates'])\n",
    "    S = mol['species']\n",
    "    symbols = np.array([mapping[atom] for atom in S])\n",
    "    symbols = np.tile(symbols, (X.shape[0], 1)) \n",
    "    symbols = torch.tensor(symbols)\n",
    "    aevs = aev_computer((symbols, X))\n",
    "    aevs_all.append(aevs)\n",
    "    \n",
    "    E = mols['energies']\n",
    "    energies.append(E)\n",
    "\n",
    "print(len(aevs_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "336fe8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd07045e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8469"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aevs_all[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd15ce1b",
   "metadata": {},
   "source": [
    "The list `all_aevs` contains the SpeciesAEV objects for all molecules in the sub-dataset. Because there are 61 molecules in subset 4, there are 61 SpeciesAEV objects. The SpeciesAEV object is a tuple that contains the mapped atom symbols for each conformation as well as the AEVs for each atom of these configurations. \n",
    "\n",
    "Energies contains the list of all energies for each conformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d880b1",
   "metadata": {},
   "source": [
    "## Neural Network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a19dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = aevs_all[:int(len(aevs_all)*0.8)]\n",
    "training_labels = energies[:int(len(energies)*0.8)]\n",
    "testing_data = aevs_all[int(len(aevs_all)*0.8):]\n",
    "testing_labels = energies[int(len(energies)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5fd735f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training molecules: 10\n",
      "Species + AEVs: 2\n",
      "Number of conformations: 8469\n",
      "Number of atoms: 8\n",
      "Number of energies: 10\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training molecules: {len(training_data)}')\n",
    "print(f'Species + AEVs: {len(training_data[0])}')\n",
    "print(f'Number of conformations: {len(training_data[0][0])}')\n",
    "print(f'Number of atoms: {len(training_data[0][0][0])}')\n",
    "print(f'Number of energies: {len(training_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75d05b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANI(nn.Module):\n",
    "    def __init__(self, architecture):\n",
    "        super().__init__()\n",
    "        self.sub_nets = nn.ModuleDict({\"C\": ANI_sub(architecture), \n",
    "                                       \"H\": ANI_sub(architecture), \n",
    "                                       \"N\": ANI_sub(architecture), \n",
    "                                       \"O\": ANI_sub(architecture)})\n",
    "        self.atom_types = {\"C\": 0, \"H\": 1, \"N\": 2, \"O\": 3}\n",
    "\n",
    "    def forward(self, aevs, atom_types):\n",
    "        atomic_energies = []\n",
    "        for i in range(len(aevs)):\n",
    "            atomic_energy = self.sub_nets[atom_types[i]](aevs[i])\n",
    "            atomic_energies.append(atomic_energy)\n",
    "\n",
    "        total_energies = torch.sum(atomic_energies, dim=0)\n",
    "        return total_energies\n",
    "\n",
    "class ANI_sub(nn.Module):\n",
    "    def __init__(self, architecture):\n",
    "        super().__init__()\n",
    "        self.fc_layers = nn.ModuleList([])\n",
    "        for i in range(len(architecture)-1):\n",
    "            self.fc_layers.append(nn.Linear(architecture[i], architecture[i+1]))\n",
    "            self.fc_layers.append(nn.ReLU())\n",
    "\n",
    "        self.fc_layers = self.fc_layers[:-1]\n",
    "        self.final_layer = nn.Linear(architecture[-2], 1)\n",
    "\n",
    "    def forward(self, aev):\n",
    "        x = aev\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        atomic_energy = self.final_layer(x)\n",
    "        return atomic_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7065ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        print('func:%r  took: %2.4f sec' % (f.__name__,  te-ts))\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ddda0d",
   "metadata": {},
   "source": [
    "For Loss, I am planning to use Mean Squared Error since the model is predicting a specific value rather than classifying the data. I will need to implement a threshold when testing the accuracy of the model as to how close the prediction is to the actual energy value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14c245f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(complete_list, chunk_size=None, num_chunks=None):\n",
    "    '''\n",
    "    Cut a list into multiple chunks, each having chunk_size (the last chunk might be less than chunk_size) or having a total of num_chunk chunks\n",
    "    '''\n",
    "    chunks = []\n",
    "    if num_chunks is None:\n",
    "        num_chunks = math.ceil(len(complete_list) / chunk_size)\n",
    "    elif chunk_size is None:\n",
    "        chunk_size = math.ceil(len(complete_list) / num_chunks)\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(complete_list[i * chunk_size: (i + 1) * chunk_size])\n",
    "    return chunks\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, optimizer_type, learning_rate, epoch, batch_size, input_transform=lambda x: x):\n",
    "        \"\"\" The class for training the model\n",
    "        model: nn.Module\n",
    "            A pytorch model\n",
    "        optimizer_type: 'adam' or 'sgd'\n",
    "        learning_rate: float\n",
    "        epoch: int\n",
    "        batch_size: int\n",
    "        input_transform: func\n",
    "            transforming input. Can do reshape here\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        if optimizer_type == \"sgd\":\n",
    "            self.optimizer = SGD(model.parameters(), learning_rate,momentum=0.9)\n",
    "        elif optimizer_type == \"adam\":\n",
    "            self.optimizer = Adam(model.parameters(), learning_rate)\n",
    "            \n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.input_transform = input_transform\n",
    "\n",
    "\n",
    "    @timing\n",
    "    def train(self, inputs, outputs, val_inputs, val_outputs,early_stop=False,l2=False,silent=False):\n",
    "        \"\"\" train self.model with specified arguments\n",
    "        inputs: np.array, The shape of input_transform(input) should be (ndata,nfeatures)\n",
    "        outputs: np.array shape (ndata,)\n",
    "        val_nputs: np.array, The shape of input_transform(val_input) should be (ndata,nfeatures)\n",
    "        val_outputs: np.array shape (ndata,)\n",
    "        early_stop: bool\n",
    "        l2: bool\n",
    "        silent: bool. Controls whether or not to print the train and val error during training\n",
    "        \n",
    "        @return\n",
    "        a dictionary of arrays with train and val losses and accuracies\n",
    "        \"\"\"\n",
    "        ### convert data to correct shape using self.input_transform ###\n",
    "        inputs = self.input_transform(inputs)\n",
    "        val_inputs = self.input_transform(val_inputs)\n",
    "        ### convert data to torch tensors ###\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float)\n",
    "        outputs = torch.tensor(outputs, dtype=torch.int64)\n",
    "        \n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        weights = self.model.state_dict()\n",
    "        lowest_val_loss = np.inf\n",
    "        \n",
    "        for n_epoch in tqdm(range(self.epoch), leave=False):\n",
    "            self.model.train()\n",
    "            batch_indices = list(range(inputs.shape[0]))\n",
    "            random.shuffle(batch_indices)\n",
    "            batch_indices = create_chunks(batch_indices, chunk_size=self.batch_size)\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            for batch in batch_indices:\n",
    "                batch_importance = len(batch) / len(outputs)\n",
    "                batch_input = inputs[batch]\n",
    "                batch_output = outputs[batch]\n",
    "                ### make prediction and compute loss with loss function of your choice on this batch ###\n",
    "                batch_predictions = self.model(batch_input)\n",
    "                loss = nn.MSELoss()(batch_predictions, batch_output)\n",
    "                if l2:\n",
    "                    ### Compute the loss with L2 regularization ###\n",
    "                    l2_lambda = 1e-5\n",
    "                    l2_norm = sum([p.pow(2.0).sum() for p in self.model.parameters()])\n",
    "                    loss = loss + l2_lambda * l2_norm\n",
    "                ### Backpropagation ###\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                ### Compute epoch_loss and epoch_acc\n",
    "                epoch_loss += loss.detach().item() * batch_importance\n",
    "                pred = torch.argmax(batch_predictions, axis=-1)\n",
    "                acc = torch.sum(pred == batch_output) / len(batch_output)\n",
    "                epoch_acc += acc.detach().item() * batch_importance\n",
    "            val_loss, val_acc = self.evaluate(val_inputs, val_outputs, print_acc=False)\n",
    "            if n_epoch % 10 == 0 and not silent: \n",
    "                print(\"Epoch %d/%d - Loss: %.3f - Acc: %.3f\" % (n_epoch + 1, self.epoch, \n",
    "                                                                epoch_loss, epoch_acc))\n",
    "                print(\"              Val_loss: %.3f - Val_acc: %.3f\" % (val_loss, val_acc))\n",
    "            losses.append(epoch_loss)\n",
    "            accuracies.append(epoch_acc)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_acc)\n",
    "            if early_stop:\n",
    "                if val_loss < lowest_val_loss:\n",
    "                    lowest_val_loss = val_loss\n",
    "                    weights = self.model.state_dict()\n",
    "\n",
    "        if early_stop:\n",
    "            self.model.load_state_dict(weights)    \n",
    "\n",
    "        return {\"losses\": losses, \"accuracies\": accuracies, \"val_losses\": val_losses, \n",
    "                \"val_accuracies\": val_accuracies}\n",
    "        \n",
    "    def evaluate(self, inputs, outputs, print_acc=True):\n",
    "        \"\"\" evaluate model on provided input and output\n",
    "        inputs: np.array, The shape of input_transform(input) should be (ndata,nfeatures)\n",
    "        outputs: np.array shape (ndata,)\n",
    "        print_acc: bool\n",
    "        \n",
    "        @return\n",
    "        losses: float\n",
    "        acc: float\n",
    "        \"\"\"\n",
    "        ### convert data to correct shape using self.input_transform ###\n",
    "        inputs = self.input_transform(inputs)\n",
    "        ### convert data to torch tensors ###\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float)\n",
    "        outputs = torch.tensor(outputs, dtype=torch.int64)\n",
    "        \n",
    "        self.model.eval() \n",
    "        batch_indices = list(range(inputs.shape[0]))\n",
    "        batch_indices = create_chunks(batch_indices, chunk_size=self.batch_size)\n",
    "        acc = 0\n",
    "        losses = 0\n",
    "        for batch in batch_indices:\n",
    "            batch_importance = len(batch) / len(outputs)\n",
    "            batch_input = inputs[batch]\n",
    "            batch_output = outputs[batch]\n",
    "            with torch.no_grad():\n",
    "                ### Compute predictions and loss ###\n",
    "                batch_predictions = self.model(batch_input)\n",
    "                loss = nn.MSELoss()(batch_predictions, batch_output)\n",
    "            pred = torch.argmax(batch_predictions, axis=-1)\n",
    "            batch_acc = torch.sum(pred == batch_output) / len(batch_output)\n",
    "            losses += loss.detach().item() * batch_importance\n",
    "            acc += batch_acc.detach().item() * batch_importance\n",
    "        if print_acc:\n",
    "            print(\"Accuracy: %.3f\" % acc)\n",
    "        return losses, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d095f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
