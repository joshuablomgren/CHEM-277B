{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ca07b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import pyanitools as pya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7408a56",
   "metadata": {},
   "source": [
    "# CHEM 277B - HW 10: Recurrent Neural Network, LSTM #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce62f2",
   "metadata": {},
   "source": [
    "## 1. LSTM applied to SMILES string generation ##\n",
    "\n",
    "Using the SMILES string from the ANI\n",
    "dataset with up to 6 heavy atoms, build a LSTM generative model that can generate new smiles string\n",
    "with given initial character."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91c599",
   "metadata": {},
   "source": [
    "## (a) ## \n",
    "\n",
    "Process the smiles strings from ANI dataset by adding a starting character at the beginning\n",
    "and an ending character at the end. Look over the dataset and define the vocabulary, use one hot\n",
    "encoding to encode your smiles strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27eee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ANI-1 dataset with 6 heavy atom\n",
    "ani_data = pya.anidataloader('../Final_Project/ANI-1_release/ani_gdb_s06.h5')\n",
    "data_iter = ani_data.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc60048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SMILES strings from ANI dataset\n",
    "ani_smiles = []\n",
    "for molecule in data_iter:\n",
    "    smiles = molecule['smiles']\n",
    "    smiles = \"\".join(smiles)\n",
    "    ani_smiles.append(smiles)\n",
    "    \n",
    "# Add starting and ending character to smiles strings\n",
    "ani_smiles = ['S' + s + 'E' for s in ani_smiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a73dbc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define vocabulary \n",
    "vocabulary = list(set(\"\".join(ani_smiles)))\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91abed0",
   "metadata": {},
   "source": [
    "There are 17 unique values including the starting and ending characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42a37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(categories=[vocabulary])\n",
    "encoder.fit(np.array(vocabulary).reshape(-1, 1))\n",
    "\n",
    "smiles_vocab = []\n",
    "for s in ani_smiles:\n",
    "    # Convert the SMILES string to a list of indices in the vocabulary\n",
    "    smiles_list = np.array(list(s)).reshape(-1,1)\n",
    "    smiles_vocab.append(smiles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e042bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_gen(smiles, batchsize, encoder):\n",
    "    '''Create a generator that returns batches of size (batch_size,seq_leng,nchars) from smiles, \n",
    "    where seq_leng is the length of the longest smiles string and nchar is the length of one-hot encoded characters (17)\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       smiles: python list(nsmiles,nchar) smiles array shape you want to make batches from\n",
    "       batchsize: Batch size, the number of sequences per batch\n",
    "       encoder: one hot encoder\n",
    "\n",
    "    '''\n",
    "    arr=[torch.tensor(np.array(encoder.transform(np.array(s).reshape(-1,1)).toarray()),dtype=torch.float) for s in smiles] \n",
    "        #size (nsmiles,seq_length(variable),nchars)\n",
    "        \n",
    "    # The features\n",
    "    X = [s[:-1,:] for s in arr]\n",
    "    # The targets, shifted by one\n",
    "    y = [s[1:,:] for s in arr]\n",
    "    # pad sequence so that all smiles are the same length\n",
    "    X = nn.utils.rnn.pad_sequence(X,batch_first=True)\n",
    "    y = nn.utils.rnn.pad_sequence(y,batch_first=True)\n",
    "\n",
    "    \n",
    "    for i in range(len(arr)//batchsize):\n",
    "        yield X[i*batchsize:(i+1)*batchsize],y[i*batchsize:(i+1)*batchsize]\n",
    "        \n",
    "    #drop last batch that is not the same size due to hidden state constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f609de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = batches_gen(smiles_vocab, 32, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e49e3534",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([32, 73, 17])\n",
      "y_batch shape: torch.Size([32, 73, 17])\n"
     ]
    }
   ],
   "source": [
    "# Get the first batch\n",
    "X_batch, y_batch = next(batches)\n",
    "\n",
    "# Print the shape of the batch data\n",
    "print('X_batch shape:', X_batch.shape)\n",
    "print('y_batch shape:', y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea48b365",
   "metadata": {},
   "source": [
    "## (b) ##\n",
    "\n",
    "Build a LSTM model with 1 recurrent layer. Starting with the starting character and grow\n",
    "a string character by character using model prediction until it reaches a ending character. Look\n",
    "at the string you grown, is it a valid SMILES string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da6efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.n_layers = num_layers\n",
    "        self.n_hidden = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=17,\n",
    "            hidden_size=self.n_hidden,\n",
    "            num_layers=self.n_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out = nn.Linear(self.n_hidden, 17)\n",
    "        \n",
    "\n",
    "    def forward(self, x, h_state):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        r_out, h_state = self.lstm(x, h_state)\n",
    "        outs = self.out(r_out)\n",
    "        return outs, h_state\n",
    "    \n",
    "    def init_state(self, batch_size):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.n_hidden), # hidden state\n",
    "                torch.zeros(self.n_layers, batch_size, self.n_hidden)) # cell state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc6c729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a method to generate the next character\n",
    "def predict(net, inputs, h, top_k=None):\n",
    "        ''' Given a onehot encoded character, predict the next character.\n",
    "            Returns the predicted onehot encoded character and the hidden state.\n",
    "        Arguments:\n",
    "            net: the lstm model\n",
    "            inputs: input to the lstm model. shape (batch, time_step/length_of_smiles, input_size) with batchsize of 1\n",
    "            h: hidden state (h,c)\n",
    "            top_k: int. sample from top k possible characters\n",
    "            \n",
    "        '''\n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])  # hidden state, detached from history\n",
    "        # get the output and new hidden state of the model\n",
    "        out, h = net(inputs, h) \n",
    "        # get the character probabilities #[1, 17], the probability that the character will be that one-hot encoded char\n",
    "        # i.e. [0.2, 0.5, 0.3, ...]  C, H, O, ...\n",
    "        p = out.data\n",
    "\n",
    "        # get top characters, i.e if top_k = 2, we will only get 0.5, 0.3 from p\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(net.chars)) #index to choose from\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        # select the likely next character with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum()) # char is index of char we want to choose\n",
    "        # return the onehot encoded value of the predicted char and the hidden state\n",
    "        output = np.zeros(inputs.detach().numpy().shape)\n",
    "        output[:,:,char] = 1\n",
    "        output = torch.tensor(output,dtype=torch.float)\n",
    "        return output, h\n",
    "\n",
    "# Declaring a method to generate new text\n",
    "def sample(net, encoder, prime=['SOS'], top_k=None):\n",
    "    \"\"\"generate a smiles string starting from prime. I use 'SOS' (start of string) and 'EOS'(end of string). \n",
    "    You may need to change this based on your starting and ending character.\n",
    "\n",
    "    \"\"\"\n",
    "    net.eval() # eval mode - gradient not calculated\n",
    "    # get initial hidden state with batchsize 1\n",
    "    h = net.init_state(1)  # batchsize = 1, hidden state\n",
    "    # First off, run through the prime characters\n",
    "    chars=[]  # the new smiles string\n",
    "    for ch in prime:\n",
    "        ch = encoder.transform(np.array([ch]).reshape(-1, 1)).toarray() #(1,17)\n",
    "        ch = torch.tensor(ch,dtype=torch.float).reshape(1,1,17)\n",
    "        char, h = predict(net, ch, h, top_k=top_k)\n",
    "    chars.append(char)\n",
    "    end  = encoder.transform(np.array(['E']).reshape(-1, 1)).toarray()\n",
    "    end = torch.tensor(end,dtype=torch.float).reshape(1,1,17)\n",
    "\n",
    "    # Now pass in the previous character and get a new one\n",
    "    while not torch.all(end.eq(chars[-1])):  # keep going till you get EOS\n",
    "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "    chars =[c.detach().numpy() for c in chars]\n",
    "    chars = np.array(chars).reshape(-1,17)\n",
    "    chars = encoder.inverse_transform(chars).reshape(-1)\n",
    "    # chars should be like ['C', '(', 'H', ')'] \n",
    "    return ''.join(chars[:-1])  # => 'C(H)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3137aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train(net, input, encoder, optimizer, loss_func, epochs, batch_size, print_every=10):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for batch, (X, y) in enumerate(batches_gen(input, 32, encoder)):\n",
    "            optimizer.zero_grad()\n",
    "            h_state, c_state = lstm.init_state(batch_size)\n",
    "            output, (h_state, c_state) = lstm(X, (h_state, c_state))\n",
    "            loss = loss_func(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % batch_size == 0 and epoch % print_every == 0:\n",
    "                print(f'Epoch {epoch}, Batch {batch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71cb95f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 0.03957372531294823\n",
      "Epoch 0, Batch 32, Loss: 0.02523517608642578\n",
      "Epoch 10, Batch 0, Loss: 0.008870486170053482\n",
      "Epoch 10, Batch 32, Loss: 0.009603436104953289\n",
      "Epoch 20, Batch 0, Loss: 0.007819849997758865\n",
      "Epoch 20, Batch 32, Loss: 0.008486508391797543\n",
      "Epoch 30, Batch 0, Loss: 0.007130241487175226\n",
      "Epoch 30, Batch 32, Loss: 0.007927707396447659\n",
      "Epoch 40, Batch 0, Loss: 0.006713942624628544\n",
      "Epoch 40, Batch 32, Loss: 0.007701043970882893\n",
      "Epoch 50, Batch 0, Loss: 0.006401564460247755\n",
      "Epoch 50, Batch 32, Loss: 0.007114299573004246\n",
      "Epoch 60, Batch 0, Loss: 0.0061504049226641655\n",
      "Epoch 60, Batch 32, Loss: 0.0068791271187365055\n",
      "Epoch 70, Batch 0, Loss: 0.00598067557439208\n",
      "Epoch 70, Batch 32, Loss: 0.006749395281076431\n",
      "Epoch 80, Batch 0, Loss: 0.005845559295266867\n",
      "Epoch 80, Batch 32, Loss: 0.006755669601261616\n",
      "Epoch 90, Batch 0, Loss: 0.005826697684824467\n",
      "Epoch 90, Batch 32, Loss: 0.006512104067951441\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(hidden_size=32)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=1e-3)\n",
    "loss_func = nn.MSELoss()\n",
    "# Training the model\n",
    "train(lstm, smiles_vocab, encoder, optimizer, loss_func, epochs=100, batch_size=32, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6eeb91b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[H]C([H])([H])N(C1([H])[H])C1([H])C([H])([H])[H]'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(lstm, encoder, prime=['S'], top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2012f",
   "metadata": {},
   "source": [
    "![molecule](molecule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81431e71",
   "metadata": {},
   "source": [
    "The LSTM model was able to produce a valid SMILES string of a molecule!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
